import pymc as pm
import numpy as np
import pandas as pd
import arviz as az
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_curve, auc

# ðŸ”¹ NumPy ã®ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®šï¼ˆPyMC ã®ãƒ©ãƒ³ãƒ€ãƒ æ€§ã«ã‚‚å½±éŸ¿ï¼‰
np.random.seed(42)

# å„æˆç¸¾ã§ãƒ™ã‚¤ã‚ºãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›žå¸°åˆ†æž
for A_col, f_col in zip(A_cols, formal_cols):
    print('')
    print(f'============================================{f_col}============================================')
    
    # èª¬æ˜Žå¤‰æ•°
    X = df[['age', 'gender', 'education_year', A_col]].copy()
    
    # ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    X = pd.get_dummies(X, columns=['gender'], drop_first=True, dtype=int) 
    
    # ç›®çš„å¤‰æ•°
    y = (df['group'] == 'ci').astype(int).values  # numpy é…åˆ—ã«å¤‰æ›
    
    # æ¨™æº–åŒ–
    scaler = StandardScaler()
    num_cols = ['age', 'education_year', A_col]  # æ¨™æº–åŒ–å¯¾è±¡ã®æ•°å€¤ã‚«ãƒ©ãƒ 
    X[num_cols] = scaler.fit_transform(X[num_cols])
    
    # PyMCã«ã‚ˆã‚‹ãƒ™ã‚¤ã‚ºãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›žå¸°
    with pm.Model() as bayesian_logit_model:
        Î²_age = pm.Normal("Î²_age", mu=0, sigma=1)
        Î²_edu = pm.Normal("Î²_edu", mu=0, sigma=1)
        Î²_gender = pm.Normal("Î²_gender", mu=0, sigma=1)
        Î²_measure = pm.Normal("Î²_measure", mu=0, sigma=1)
        intercept = pm.Normal("intercept", mu=0, sigma=2)
        
        # ç·šå½¢çµåˆ
        Î¼ = (
            intercept
            + Î²_age * X["age"].values
            + Î²_edu * X["education_year"].values
            + Î²_gender * X["gender_M"].values
            + Î²_measure * X[A_col].values
        )
        
        # ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°ã§ç¢ºçŽ‡ã‚’å¾—ã‚‹
        p = pm.math.sigmoid(Î¼)
        
        # ãƒ™ãƒ«ãƒŒãƒ¼ã‚¤åˆ†å¸ƒã®å°¤åº¦
        likelihood = pm.Bernoulli("y", p=p, observed=y)
        
        # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        trace_bayes_logit = pm.sample(2000, tune=1000, target_accept=0.98, return_inferencedata=True)
    
    # äº‹å¾Œåˆ†å¸ƒã®è¦ç´„
    summary = az.summary(trace_bayes_logit, stat_funcs={"median": np.median}, hdi_prob=0.95)
    print(summary)
    
    # ã‚ªãƒƒã‚ºæ¯”ã‚’è¨ˆç®—
    odds_ratios = np.exp(summary['median'])
    print("\nã‚ªãƒƒã‚ºæ¯”:")
    print(odds_ratios)

    odds_ratios_lower = np.exp(summary['hdi_2.5%'])
    print("\nã‚ªãƒƒã‚ºæ¯”ä¸‹é™:")
    print(odds_ratios_lower)

    odds_ratios_upper = np.exp(summary['hdi_97.5%'])
    print("\nã‚ªãƒƒã‚ºæ¯”ä¸Šé™:")
    print(odds_ratios_upper)
    
    # äº‹å¾Œç¢ºçŽ‡ã‚’è¨ˆç®—
    def compute_posterior_probabilities(trace, param):
        """äº‹å¾Œç¢ºçŽ‡ã‚’æ±‚ã‚ã‚‹"""
        samples = trace.posterior[param].values.flatten()
        prob_positive = (samples > 0).mean()
        prob_negative = (samples < 0).mean()
        return prob_positive, prob_negative
    
    print("\näº‹å¾Œç¢ºçŽ‡:")
    for param in ["Î²_age", "Î²_edu", "Î²_gender", "Î²_measure"]:
        p_pos, p_neg = compute_posterior_probabilities(trace_bayes_logit, param)
        print(f"{param}: P(Î² > 0) = {p_pos:.3f}, P(Î² < 0) = {p_neg:.3f}")
    
    # äºˆæ¸¬ç¢ºçŽ‡ã‚’å–å¾—
    with bayesian_logit_model:
        posterior_pred = pm.sample_posterior_predictive(trace_bayes_logit, var_names=["y"])
    
    # äº‹å¾Œåˆ†å¸ƒã®å¹³å‡ã‚’è¨ˆç®—
    pred_prob = posterior_pred.posterior_predictive["y"].mean(dim=["chain", "draw"]).values  
    
    # ROCæ›²ç·šã®ä½œæˆ
    fpr, tpr, thresholds = roc_curve(y, pred_prob)  
    roc_auc = auc(fpr, tpr)
    youden_index = tpr - fpr
    best_threshold = thresholds[np.argmax(youden_index)]

    # æœ€é©ã‚¹ã‚³ã‚¢ã‚’å¾—ã‚‹é–¢æ•°
    def get_optimal_score(trace, scaler, target_prob, age, education_year, gender):
        """ 
        å¹´é½¢ãƒ»æ•™è‚²æ­´ãƒ»æ€§åˆ¥ã‚’å…¥åŠ›ã—ã€ãƒ™ã‚¤ã‚ºãƒ¢ãƒ‡ãƒ«ã®äº‹å¾Œåˆ†å¸ƒã‚’ç”¨ã„ã¦
        èªçŸ¥æ¤œæŸ»ã‚¹ã‚³ã‚¢ã®æœ€é©é–¾å€¤ã‚’æ±‚ã‚ã‚‹é–¢æ•°
        """
        
        # äº‹å¾Œåˆ†å¸ƒã®å¹³å‡å€¤ï¼ˆMAPæŽ¨å®šï¼‰
        intercept = trace.posterior["intercept"].mean().item()
        Î²_age = trace.posterior["Î²_age"].mean().item()
        Î²_edu = trace.posterior["Î²_edu"].mean().item()
        Î²_gender = trace.posterior["Î²_gender"].mean().item()
        Î²_measure = trace.posterior["Î²_measure"].mean().item()
    
        # æ¨™æº–åŒ– (scaler ã‹ã‚‰å–å¾—)
        age_scaled = (age - scaler.mean_[0]) / scaler.scale_[0]
        edu_scaled = (education_year - scaler.mean_[1]) / scaler.scale_[1]
        gender_binary = 1 if gender == "M" else 0  # æ€§åˆ¥ã‚’æ•°å€¤åŒ–
    
        # `A_col` ã®ã‚¹ã‚³ã‚¢ã®é–¾å€¤ã‚’è¨ˆç®—ï¼ˆp = sigmoid(intercept + ... + Î²_measure * A) ã®é€†ç®—ï¼‰
        A_threshold_scaled = (np.log(target_prob / (1 - target_prob)) - 
                              (intercept + Î²_age * age_scaled + Î²_edu * edu_scaled + Î²_gender * gender_binary)) / Î²_measure
        
        # é€†æ¨™æº–åŒ–ï¼ˆå…ƒã®ã‚¹ã‚³ã‚¢ã«æˆ»ã™ï¼‰
        A_threshold = A_threshold_scaled * scaler.scale_[2] + scaler.mean_[2]  
    
        return A_threshold
    
    scaler = StandardScaler()
    scaler.fit(df_hs[['age', 'education_year', A_col]]) 
    
    score_threshold = get_optimal_score(
        trace_bayes_logit, scaler, best_threshold, 40, 12, "M"
    )
    print(f"40æ­³ãƒ»æ•™è‚²12å¹´ãƒ»ç”·æ€§ã®æœ€é©ã‚¹ã‚³ã‚¢é–¾å€¤: {score_threshold:.3f}")
    
    # é–¾å€¤ã®è¨ˆç®—å¼ã‚’å‡ºåŠ›
    def print_threshold_equation(trace, p_star, scaler):
        """å­¦ç¿’æ¸ˆã¿ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ã„ã€é–¾å€¤ã®è¨ˆç®—å¼ã‚’ç”Ÿæˆ"""
        Î²_0 = trace.posterior["intercept"].mean().item()
        Î²_age = trace.posterior["Î²_age"].mean().item()
        Î²_edu = trace.posterior["Î²_edu"].mean().item()
        Î²_gender = trace.posterior["Î²_gender"].mean().item()
        Î²_measure = trace.posterior["Î²_measure"].mean().item()
        
        print("\né–¾å€¤è¨ˆç®—å¼:")
        print(f"score_scaled = (log({p_star:.3f} / (1 - {p_star:.3f})) - ({Î²_0:.3f} + {Î²_age:.3f} * ((age - {scaler.mean_[0]:.3f}) / {scaler.scale_[0]:.3f}) + {Î²_edu:.3f} * ((education_year - {scaler.mean_[1]:.3f}) / {scaler.scale_[1]:.3f}) + {Î²_gender} * gender_binary) / {Î²_measure:.3f})")
        print(f"score = score_scaled * {scaler.scale_[2]:.3f} + {scaler.mean_[2]:.3f}")
        print('genderã¯M:1, F:0')
    
    print_threshold_equation(trace_bayes_logit, best_threshold, scaler)